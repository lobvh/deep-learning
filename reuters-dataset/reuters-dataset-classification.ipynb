{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARY\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mini-project we have a problem of single label, multiclass classification. The dataset we are using is 'Reuters dataset', which is already included in the Keras package. Reuters dataset is a set of short newswires and their topics, published by Reuters in 1986. Each newswire belongs to one of the 46 different topic. \n",
    "It's a multiclass problem, because there are 46 different topics, yet single label since each data point has one-to-one corespodence with one of the 46 topics. \n",
    "\n",
    "This problem is 'almost the same' with the binary classification one, and the differences are as follows:\n",
    "\n",
    "* What sigmoid is for binary classification, soft-max is for multiclass classification\n",
    "* Since the dimension of output space is 46 we should 'not' include information bottleneck. That is, previous layers have less dimensions (aka units) than the (final) output layer/s, and hence compressing too much information which could help to make separation hyperplanes of 46 classes is a bad juju!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset from Keras dataset library\n",
    "from keras.datasets import reuters\n",
    "\n",
    "#Importing libraries for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing libraries for everything that deals with modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.metrics import accuracy\n",
    "\n",
    "#For making ticks integer values\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing training and test part of the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we are gonna stick to first 10000 most frequently used words to make learning feasible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), (2246,), (8982,), (2246,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checks to see if we imported data properly\n",
    "\n",
    "train_data.shape, test_data.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8982 newswires in training, and 2246 in the test set. Close to 80%/20% split. Now we will see one of the decoded newswires and explore all the unique topics that those newswires are associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding first newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index() # {'word':'frequency_of_word'}\n",
    "reverse_word_index = dict([(value, key)\n",
    "                             for (key, value) in word_index.items()]) # {'frequency_of_word':'word'}\n",
    "\n",
    "#Let's decode the first newswire in our training dataset\n",
    "decoded_review_1 = ' '.join([reverse_word_index.get(i-3, '?')\n",
    "                              for i in train_data[0]])\n",
    "decoded_review_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels), np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive approach forgeting that most frequent words are for the newswires, not for unique labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_topics = []\n",
    "for idx in np.unique(train_labels):\n",
    "    list_of_topics.append(reverse_word_index.get(idx))\n",
    "    \n",
    "#list_of_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the orginal ones scraped from the web: \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_topics = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "                  'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "                  'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "                  'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "                  'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/SteffenBauer/KerasTools/blob/master/KerasTools/datasets/decode.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
